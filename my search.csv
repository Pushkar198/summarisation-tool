INDEX,SEARCHED KEYWORD,PAPER TITLE,AUTHER NAME,URL,YEAR,ABSTRACT,SUMMARY
0,reservoir computing in WSN,An experimental characterization of reservoir computing in ambient assisted living applications,"D Bacciu, P Barsocchi, S Chessa, C Gallicchio… - Neural Computing and …, 2014 - Springer",https://link.springer.com/article/10.1007/s00521-013-1364-4,2014,"In this paper, we present an introduction and critical experimental evaluation of a reservoir computing (RC) approach for ambient assisted living (AAL) applications. Such an empirical analysis jointly addresses the issues of efficiency, by analyzing different system configurations toward the embedding into computationally constrained wireless sensor devices, and of efficacy, by analyzing the predictive performance on real-world applications. First, the approach is assessed on a validation scheme where training, validation and test data are sampled in homogeneous ambient conditions, i.e., from the same set of rooms. Then, it is introduced an external test set involving a new setting, i.e., a novel ambient, which was not available in the first phase of model training and validation. The specific test-bed considered in the paper allows us to investigate the capability of the RC approach to discriminate among user movement trajectories from received signal strength indicator sensor signals. This capability can be exploited in various AAL applications targeted at learning user indoor habits, such as in the proposed indoor movement forecasting task. Such a joint analysis of the efficiency/efficacy trade-off provides novel insight in the concrete successful exploitation of RC for AAL tasks and for their distributed implementation into wireless sensor networks.",Such a joint analysis of the efficiency/efficacy trade-off provides novel insight in the concrete successful exploitation of RC for AAL tasks and for their distributed implementation into wireless sensor networks.
1,reservoir computing in WSN,Human activity recognition using multisensor data fusion based on reservoir computing,"F Palumbo, C Gallicchio, R Pucci… - Journal of Ambient …, 2016 - content.iospress.com",https://content.iospress.com/articles/journal-of-ambient-intelligence-and-smart-environments/ais372,2016,"Activity recognition plays a key role in providing activity assistance and care for users in smart homes. In this work, we present an activity recognition system that classifies in the near real-time a set of common daily activities exploiting both the data sampled by sensors embedded in a smartphone carried out by the user and the reciprocal Received Signal Strength (RSS) values coming from worn wireless sensor devices and from sensors deployed in the environment. In order to achieve an effective and responsive classification, a decision tree based on multisensor data-stream is applied fusing data coming from embedded sensors on the smartphone and environmental sensors before processing the RSS stream. To this end, we model the RSS stream, obtained from a Wireless Sensor Network (WSN), using Recurrent Neural Networks (RNNs) implemented as efficient Echo State Networks (ESNs), within the Reservoir Computing (RC) paradigm. We targeted the system for the EvAAL scenario, an international competition that aims at establishing benchmarks and evaluation metrics for comparing Ambient Assisted Living (AAL) solutions. In this paper, the performance of the proposed activity recognition system is assessed on a purposely collected real-world dataset, taking also into account a competitive neural network approach for performance comparison. Our results show that, with an appropriate configuration of the information fusion chain, the proposed system reaches a very good accuracy with a low deployment cost. ","In this work, we present an activity recognition system that classifies in the near real-time a set of common daily activities exploiting both the data sampled by sensors embedded in a smartphone carried out by the user and the reciprocal Received Signal Strength (RSS) values coming from worn wireless sensor devices and from sensors deployed in the environment."
2,reservoir computing in WSN,Multisensor data fusion for activity recognition based on reservoir computing,"F Palumbo, P Barsocchi, C Gallicchio, S Chessa… - Evaluating AAL Systems …, 2013 - Springer",https://link.springer.com/chapter/10.1007/978-3-642-41043-7_3,2013,"Ambient Assisted Living facilities provide assistance and care for the elderly, where it is useful to infer their daily activity for ensuring their safety and successful ageing. In this work, we present an Activity Recognition system that classifies a set of common daily activities exploiting both the data sampled by accelerometer sensors carried out by the user and the reciprocal Received Signal Strength (RSS) values coming from worn wireless sensor devices and from sensors deployed in the environment. To this end, we model the accelerometer and the RSS stream, obtained from a Wireless Sensor Network (WSN), using Recurrent Neural Networks implemented as efficient Echo State Networks (ESNs), within the Reservoir Computing paradigm. Our results show that, with an appropriate configuration of the ESN, the system reaches a good accuracy with a low deployment cost.KeywordsAALActivity RecognitionNeural NetworksSensor Data FusionWSN","In this work, we present an Activity Recognition system that classifies a set of common daily activities exploiting both the data sampled by accelerometer sensors carried out by the user and the reciprocal Received Signal Strength (RSS) values coming from worn wireless sensor devices and from sensors deployed in the environment."
3,reservoir computing in WSN,User movements forecasting by reservoir computing using signal streams produced by mote-class sensors,"C Gallicchio, A Micheli, P Barsocchi… - … Wireless Systems: Third …, 2012 - Springer",https://link.springer.com/chapter/10.1007/978-3-642-29479-2_12,2012,"Real-time, indoor user localization, although limited to the current user position, is of great practical importance in many Ambient Assisted Living (AAL) applications. Moreover, an accurate prediction of the user next position (even with a short advice) may open a number of new AAL applications that could timely provide the right services in the right place even before the user request them. However, the problem of forecasting the user position is complicated due to the intrinsic difficulty of localization in indoor environments, and to the fact that different paths of the user may intersect at a given point, but they may end in different places. We tackle with this problem by modeling the localization information stream obtained from a Wireless Sensor Network (WSN) using Recurrent Neural Networks implemented as efficient Echo State Networks (ESNs), within the Reservoir Computing paradigm. In particular, we have set up an experimental test-bed in which the WSN produces localization information of a user that moves along a number of different paths, and in which the ESN collects localization information to predict a future position of the user at some given mark points. Our results show that, with an appropriate configuration of the ESN, the system reaches a good accuracy of the prediction also with a small WSN, and that the accuracy scales well with the WSN size. Furthermore, the accuracy is also reasonably robust to variations in the deployment of the sensors. For these reasons our solution can be configured to meet the desired trade-off between cost and accuracy.KeywordsMovement ForecastingSensor Stream AnalysisReceived Signal StrengthEcho State NetworksWireless Sensor NetworksAmbient Assisted Living","However, the problem of forecasting the user position is complicated due to the intrinsic difficulty of localization in indoor environments, and to the fact that different paths of the user may intersect at a given point, but they may end in different places."
4,reservoir computing in WSN,Distributed reservoir computing with sparse readouts [research frontier],"S Scardapane, M Panella… - IEEE Computational …, 2016 - ieeexplore.ieee.org",https://ieeexplore.ieee.org/abstract/document/7587490/,2016,"In a network of agents, a widespread problem is the need to estimate a common underlying function starting from locally distributed measurements. Real-world scenarios may not allow the presence of centralized fusion centers, requiring the development of distributed, message-passing implementations of the standard machine learning training algorithms. In this paper, we are concerned with the distributed training of a particular class of recurrent neural networks, namely echo state networks (ESNs). In the centralized case, ESNs have received considerable attention, due to the fact that they can be trained with standard linear regression routines. Based on this observation, in our previous work we have introduced a decentralized algorithm, framed in the distributed optimization field, in order to train an ESN. In this paper, we focus on an additional sparsity property of the output layer of ESNs, allowing for very efficient implementations of the resulting networks. In order to evaluate the proposed algorithm, we test it on two well-known prediction benchmarks, namely the Mackey-Glass chaotic time series and the 10th order nonlinear auto regressive moving average (NARMA) system.","In this paper, we focus on an additional sparsity property of the output layer of ESNs, allowing for very efficient implementations of the resulting networks."
5,reservoir computing in WSN,Digital implementation of a single dynamical node reservoir computer,"ML Alomar, MC Soriano… - … on Circuits and …, 2015 - ieeexplore.ieee.org",https://ieeexplore.ieee.org/abstract/document/7161321/,2015,"Minimal hardware implementations of machine-learning techniques have been attracting increasing interest over the last decades. In particular, field-programmable gate array (FPGA) implementations of neural networks (NNs) are among the most appealing ones, given the match between system requirements and FPGA properties, namely, parallelism and adaptation. Here, we present an FPGA implementation of a conceptually simplified version of a recurrent NN based on a single dynamical node subject to delayed feedback. We show that this configuration is capable of successfully performing simple real-time temporal pattern classification and chaotic time-series prediction.","In particular, field-programmable gate array (FPGA) implementations of neural networks (NNs) are among the most appealing ones, given the match between system requirements and FPGA properties, namely, parallelism and adaptation."
6,reservoir computing in WSN,DropIn: Making reservoir computing neural networks robust to missing inputs by dropout,"D Bacciu, F Crecchi, D Morelli - 2017 International Joint …, 2017 - ieeexplore.ieee.org",https://ieeexplore.ieee.org/abstract/document/7966106/,2017,"The paper presents a novel, principled approach to train recurrent neural networks from the Reservoir Computing family that are robust to missing part of the input features at prediction time. By building on the ensembling properties of Dropout regularization, we propose a methodology, named DropIn, which efficiently trains a neural model as a committee machine of subnetworks, each capable of predicting with a subset of the original input features. We discuss the application of the DropIn methodology in the context of Reservoir Computing models and targeting applications characterized by input sources that are unreliable or prone to be disconnected, such as in pervasive wireless sensor networks and ambient intelligence. We provide an experimental assessment using real-world data from such application domains, showing how the Dropin methodology allows to maintain predictive performances comparable to those of a model without missing features, even when 20%–50% of the inputs are not available.","We discuss the application of the DropIn methodology in the context of Reservoir Computing models and targeting applications characterized by input sources that are unreliable or prone to be disconnected, such as in pervasive wireless sensor networks and ambient intelligence."
7,reservoir computing in WSN,Predicting user movements in heterogeneous indoor environments by reservoir computing,"D Bacciu, C Gallicchio, A Micheli, S Chessa… - Proc. of the IJCAI …, 2011 - Citeseer",https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=40c2393e1874c3fd961fdfff02402c24ccf1c3d7#page=13,2011,"… costeffectively realized on  WSNs  comprising simple computa… and their environments using    reservoir    computing  . Neural Proc…  reservoir    computing  . Neural Netw., 21 (6): 862–871, 2008. …",Neural Proc…  reservoir    computing  .
8,reservoir computing in WSN,Brain-inspired wireless communications: Where reservoir computing meets MIMO-OFDM,"SS Mosleh, L Liu, C Sahin… - IEEE transactions on …, 2017 - ieeexplore.ieee.org",https://ieeexplore.ieee.org/abstract/document/8169663/,2017,"Reservoir computing (RC) is a class of neuromorphic computing approaches that deals particularly well with time-series prediction tasks. It significantly reduces the training complexity of recurrent neural networks and is also suitable for hardware implementation whereby device physics are utilized in performing data processing. In this paper, the RC concept is applied to detecting a transmitted symbol in multiple-input multiple-output orthogonal frequency division multiplexing (MIMO-OFDM) systems. Due to wireless propagation, the transmitted signal may undergo severe distortion before reaching the receiver. The nonlinear distortion introduced by the power amplifier at the transmitter may further complicate this process. Therefore, an efficient symbol detection strategy becomes critical. The conventional approach for symbol detection at the receiver requires accurate channel estimation of the underlying MIMO-OFDM system. However, in this paper, we introduce a novel symbol detection scheme where the estimation of the MIMO-OFDM channel becomes unnecessary. The introduced scheme utilizes an echo state network (ESN), which is a special class of RC. The ESN acts as a black box for system modeling purposes and can predict nonlinear dynamic systems in an efficient way. Simulation results for the uncoded bit error rate of nonlinear MIMO-OFDM systems show that the introduced scheme outperforms conventional symbol detection methods.",The conventional approach for symbol detection at the receiver requires accurate channel estimation of the underlying MIMO-OFDM system.
9,reservoir computing in WSN,Reservoir Computing Forecasting of User Movements from RSS Mote-Class Sensors Measurement,"C Gallicchio, A Micheli, P Barsocchi, S Chessa - 2011 - eprints.adm.unipi.it",http://eprints.adm.unipi.it/2269/,2011,"… stream obtained from a  Wireless    Sensor    Network  (  WSN  ) using Recurrent … the  Reservoir      Computing  paradigm. In particular, we have set up an experimental test-bed in which the  WSN  …","In particular, we have set up an experimental test-bed in which the  WSN  …"
10,recurrent network for time series data ,Recurrence networks—a novel paradigm for nonlinear time series analysis,"RV Donner, Y Zou, JF Donges, N Marwan… - New Journal of …, 2010 - iopscience.iop.org",https://iopscience.iop.org/article/10.1088/1367-2630/12/3/033025/meta,2010,"
17481 Total downloads

","
17481 Total downloads

"
11,recurrent network for time series data ,Convolutional neural networks for time series classification,"B Zhao, H Lu, S Chen, J Liu… - Journal of Systems …, 2017 - ieeexplore.ieee.org",https://ieeexplore.ieee.org/abstract/document/7870510/,2017,"Time series classification is an important task in time series data mining, and has attracted great interests and tremendous efforts during last decades. However, it remains a challenging problem due to the nature of time series data: high dimensionality, large in data size and updating continuously. The deep learning techniques are explored to improve the performance of traditional feature-based approaches. Specifically, a novel convolutional neural network (CNN) framework is proposed for time series classification. Different from other feature-based classification approaches, CNN can discover and extract the suitable internal structure to generate deep features of the input time series automatically by using convolution and pooling operations. Two groups of experiments are conducted on simulated data sets and eight groups of experiments are conducted on real-world data sets from different application domains. The final experimental results show that the proposed method outperforms state-of-the-art methods for time series classification in terms of the classification accuracy and noise tolerance.","Different from other feature-based classification approaches, CNN can discover and extract the suitable internal structure to generate deep features of the input time series automatically by using convolution and pooling operations."
12,recurrent network for time series data ,A review of irregular time series data handling with gated recurrent neural networks,"PB Weerakody, KW Wong, G Wang, W Ela - Neurocomputing, 2021 - Elsevier",https://www.sciencedirect.com/science/article/pii/S0925231221003003,2021,"… dependencies in irregular univariate and multivariate  time    series    data  . In this paper, we …  gated  recurrent    neural    networks  have been successfully applied to irregular  time    series    data  for …","In this paper, we …  gated  recurrent    neural    networks  have been successfully applied to irregular  time    series    data  for …"
13,recurrent network for time series data ,Recurrent neural networks for multivariate time series with missing values,"Z Che, S Purushotham, K Cho, D Sontag, Y Liu - Scientific reports, 2018 - nature.com",https://www.nature.com/articles/s41598-018-24271-9,2018,"Multivariate time series data in practical applications, such as health care, geoscience, and biology, are characterized by a variety of missing values. In time series prediction and other related tasks, it has been noted that missing values and their missing patterns are often correlated with the target labels, a.k.a., informative missingness. There is very limited work on exploiting the missing patterns for effective imputation and improving prediction performance. In this paper, we develop novel deep learning models, namely GRU-D, as one of the early attempts. GRU-D is based on Gated Recurrent Unit (GRU), a state-of-the-art recurrent neural network. It takes two representations of missing patterns, i.e., masking and time interval, and effectively incorporates them into a deep model architecture so that it not only captures the long-term temporal dependencies in time series, but also utilizes the missing patterns to achieve better prediction results. Experiments of time series classification tasks on real-world clinical datasets (MIMIC-III, PhysioNet) and synthetic datasets demonstrate that our models achieve state-of-the-art performance and provide useful insights for better understanding and utilization of missing values in time series analysis.","Experiments of time series classification tasks on real-world clinical datasets (MIMIC-III, PhysioNet) and synthetic datasets demonstrate that our models achieve state-of-the-art performance and provide useful insights for better understanding and utilization of missing values in time series analysis."
14,recurrent network for time series data ,Recurrent neural networks and robust time series prediction,"JT Connor, RD Martin, LE Atlas - … on neural networks, 1994 - ieeexplore.ieee.org",https://ieeexplore.ieee.org/abstract/document/279188/,1994,"We propose a robust learning algorithm and apply it to recurrent neural networks. This algorithm is based on filtering outliers from the data and then estimating parameters from the filtered data. The filtering removes outliers from both the target function and the inputs of the neural network. The filtering is soft in that some outliers are neither completely rejected nor accepted. To show the need for robust recurrent networks, we compare the predictive ability of least squares estimated recurrent networks on synthetic data and on the Puget Power Electric Demand time series. These investigations result in a class of recurrent neural networks, NARMA(p,q), which show advantages over feedforward neural networks for time series with a moving average component. Conventional least squares methods of fitting NARMA(p,q) neural network models are shown to suffer a lack of robustness towards outliers. This sensitivity to outliers is demonstrated on both the synthetic and real data sets. Filtering the Puget Power Electric Demand time series is shown to automatically remove the outliers due to holidays. Neural networks trained on filtered data are then shown to give better predictions than neural networks trained on unfiltered time series.<
<ETX xmlns:mml=""http://www.w3.org/1998/Math/MathML"" xmlns:xlink=""http://www.w3.org/1999/xlink"">&gt;</ETX>","To show the need for robust recurrent networks, we compare the predictive ability of least squares estimated recurrent networks on synthetic data and on the Puget Power Electric Demand time series."
15,recurrent network for time series data ,Time series forecasting using neural networks,"T Kolarik, G Rudorfer - ACM Sigapl Apl Quote Quad, 1994 - dl.acm.org",https://dl.acm.org/doi/abs/10.1145/190468.190290,1994,"Artificial neural networks are suitable for many tasks in pattern recognition and machine learning. In this paper we present an APL system for forecasting univariate time series with artificial neural networks. Unlike conventional techniques for time series analysis, an artificial neural network needs little information about the time series data and can be applied to a broad range of problems. However, the problem of network “tuning” remains: parameters of the backpropagation algorithm as well as the network topology need to be adjusted for optimal performances. For our application, we conducted experiments to find the right parameters for a forecasting network. The artificial neural networks that were found delivered a better forecasting performance than results  obtained by the well known ARIMA technique.","Unlike conventional techniques for time series analysis, an artificial neural network needs little information about the time series data and can be applied to a broad range of problems."
16,recurrent network for time series data ,Designing a neural network for forecasting financial and economic time series,"I Kaastra, M Boyd - Neurocomputing, 1996 - Elsevier",https://www.sciencedirect.com/science/article/pii/0925231295000399,1996,… be selected to develop a  neural    network  forecasting model have meant … a  neural    network    for forecasting economic  time    series    data  . An eight-step procedure to design a  neural    network  …,An eight-step procedure to design a  neural    network  …
17,recurrent network for time series data ,Recurrent neural networks for time series classification,"M Hüsken, P Stagge - Neurocomputing, 2003 - Elsevier",https://www.sciencedirect.com/science/article/pii/S0925231201007068,2003,… the dynamics of  recurrent    neural    networks  (RNNs) for the classification of  time    series  . The  … neurons represent the class of the  time    series  fed into the  network  . The main issues of this …,The  … neurons represent the class of the  time    series  fed into the  network  .
18,recurrent network for time series data ,Evolving recurrent neural networks for time series data prediction of coal plant parameters,"AER ElSaid, S Benson, S Patwardhan… - … 2019, Held as Part of …, 2019 - Springer",https://link.springer.com/chapter/10.1007/978-3-030-16692-2_33,2019,"This paper presents the Evolutionary eXploration of Augmenting LSTM Topologies (EXALT) algorithm and its use in evolving recurrent neural networks (RNNs) for time series data prediction. It introduces a new open data set from a coal-fired power plant, consisting of 10 days of per minute sensor recordings from 12 different burners at the plant. This large scale real world data set involves complex dependencies between sensor parameters and makes for challenging data to predict. EXALT provides interesting new techniques for evolving neural networks, including epigenetic weight initialization, where child neural networks re-use parental weights as a starting point to backpropagation, as well as node-level mutation operations which can improve evolutionary progress. EXALT has been designed with parallel computation in mind to further improve performance. Preliminary results were gathered predicting the Main Flame Intensity data parameter, with EXALT strongly outperforming five traditional neural network architectures on the best, average and worst cases across 10 repeated training runs per test case; and was only slightly behind the best trained Elman recurrent neural networks while being significantly more reliable (i.e., much better average and worst case results). Further, EXALT achieved these results 2 to 10 times faster than the traditional methods, in part due to its scalability, showing strong potential to beat traditional architectures given additional runtime.KeywordsNeuro-evolutionRecurrent neural networksTime series data prediction",This paper presents the Evolutionary eXploration of Augmenting LSTM Topologies (EXALT) algorithm and its use in evolving recurrent neural networks (RNNs) for time series data prediction.
19,recurrent network for time series data ,Detecting anomalies in time series data from a manufacturing system using recurrent neural networks,"Y Wang, M Perry, D Whitlock, JW Sutherland - Journal of Manufacturing …, 2022 - Elsevier",https://www.sciencedirect.com/science/article/pii/S0278612520302211,2022,"… acquired from a manufacturing system are usually in the forms of  time    series  . This … in  time      series    data  . This model is based on  recurrent    neural    networks  , and it can be trained using  data  …",This … in  time      series    data  .
20,Deep architecture,Learning deep architectures for AI,"Y Bengio - Foundations and trends® in Machine Learning, 2009 - nowpublishers.com",https://www.nowpublishers.com/article/Details/MAL-006,2009,"Theoretical results suggest that in order to learn the kind of complicated functions that can represent high-level abstractions (e.g., in vision, language, and other AI-level tasks), one may need deep architectures. Deep architectures are composed of multiple levels of non-linear operations, such as in neural nets with many hidden layers or in complicated propositional formulae re-using many sub-formulae. Searching the parameter space of deep architectures is a difficult task, but learning algorithms such as those for Deep Belief Networks have recently been proposed to tackle this problem with notable success, beating the state-of-the-art in certain areas. This monograph discusses the motivations and principles regarding learning algorithms for deep architectures, in particular those exploiting as building blocks unsupervised learning of single-layer models such as Restricted Boltzmann Machines, used to construct deeper models such as Deep Belief Networks.","Searching the parameter space of deep architectures is a difficult task, but learning algorithms such as those for Deep Belief Networks have recently been proposed to tackle this problem with notable success, beating the state-of-the-art in certain areas."
21,Deep architecture,Practical recommendations for gradient-based training of deep architectures,"Y Bengio - Neural Networks: Tricks of the Trade: Second Edition, 2012 - Springer",https://link.springer.com/chapter/10.1007/978-3-642-35289-8_26,2012,"Learning algorithms related to artificial neural networks and in particular for Deep Learning may seem to involve many bells and whistles, called hyper-parameters. This chapter is meant as a practical guide with recommendations for some of the most commonly used hyperparameters, in particular in the context of learning algorithms based on back-propagated gradient and gradient-based optimization. It also discusses how to deal with the fact that more interesting results can be obtained when allowing one to adjust many hyper-parameters. Overall, it describes elements of the practice used to successfully and efficiently train and debug large-scale and often deep multi-layer neural networks. It closes with open questions about the training difficulties observed with deeper architectures.KeywordsDeep LearnGrid SearchHide UnitSparse CodeGeneralization ErrorThese keywords were added by machine and not by the authors. This process is experimental and the keywords may be updated as the learning algorithm improves.","Learning algorithms related to artificial neural networks and in particular for Deep Learning may seem to involve many bells and whistles, called hyper-parameters."
22,Deep architecture,Understanding representations learned in deep architectures,"D Erhan, A Courville, Y Bengio - 2010 - iro.umontreal.ca",http://www.iro.umontreal.ca/~lisa/pointeurs/invariances_techreport.pdf,2010,…  deep    architectures  as representatives of two families of models encountered in the  deep  …  verify some hypotheses that we had about  deep    architectures  : namely that they learn to model …,
23,Deep architecture,Deep unfolding: Model-based inspiration of novel deep architectures,"JR Hershey, JL Roux, F Weninger - arXiv preprint arXiv:1409.2574, 2014 - arxiv.org",https://arxiv.org/abs/1409.2574,1409," Model-based methods and deep neural networks have both been tremendously
successful paradigms in machine learning. In model-based methods, problem
domain knowledge can be built into the constraints of the model, typically at
the expense of difficulties during inference. In contrast, deterministic deep
neural networks are constructed in such a way that inference is
straightforward, but their architectures are generic and it is unclear how to
incorporate knowledge. This work aims to obtain the advantages of both
approaches. To do so, we start with a model-based approach and an associated
inference algorithm, and \emph{unfold} the inference iterations as layers in a
deep network. Rather than optimizing the original model, we \emph{untie} the
model parameters across layers, in order to create a more powerful network. The
resulting architecture can be trained discriminatively to perform accurate
inference within a fixed network size. We show how this framework allows us to
interpret conventional networks as mean-field inference in Markov random
fields, and to obtain new architectures by instead using belief propagation as
the inference algorithm. We then show its application to a non-negative matrix
factorization model that incorporates the problem-domain knowledge that sound
sources are additive. Deep unfolding of this model yields a new kind of
non-negative deep neural network, that can be trained using a multiplicative
backpropagation-style update algorithm. We present speech enhancement
experiments showing that our approach is competitive with conventional neural
networks despite using far fewer parameters.
","To do so, we start with a model-based approach and an associated
inference algorithm, and \emph{unfold} the inference iterations as layers in a
deep network."
24,Deep architecture,On the expressive power of deep architectures,"Y Bengio, O Delalleau - … Theory: 22nd International Conference, ALT 2011 …, 2011 - Springer",https://link.springer.com/content/pdf/10.1007/978-3-642-24412-4.pdf#page=30,2011,none,none
25,Deep architecture,Deeparchitect: Automatically designing and training deep architectures,"R Negrinho, G Gordon - arXiv preprint arXiv:1704.08792, 2017 - arxiv.org",https://arxiv.org/abs/1704.08792,1704," In deep learning, performance is strongly affected by the choice of
architecture and hyperparameters. While there has been extensive work on
automatic hyperparameter optimization for simple spaces, complex spaces such as
the space of deep architectures remain largely unexplored. As a result, the
choice of architecture is done manually by the human expert through a slow
trial and error process guided mainly by intuition. In this paper we describe a
framework for automatically designing and training deep models. We propose an
extensible and modular language that allows the human expert to compactly
represent complex search spaces over architectures and their hyperparameters.
The resulting search spaces are tree-structured and therefore easy to traverse.
Models can be automatically compiled to computational graphs once values for
all hyperparameters have been chosen. We can leverage the structure of the
search space to introduce different model search algorithms, such as random
search, Monte Carlo tree search (MCTS), and sequential model-based optimization
(SMBO). We present experiments comparing the different algorithms on CIFAR-10
and show that MCTS and SMBO outperform random search. In addition, these
experiments show that our framework can be used effectively for model
discovery, as it is possible to describe expressive search spaces and discover
competitive models without much effort from the human expert. Code for our
framework and experiments has been made publicly available.
","In addition, these
experiments show that our framework can be used effectively for model
discovery, as it is possible to describe expressive search spaces and discover
competitive models without much effort from the human expert."
26,Deep architecture,Swapout: Learning an ensemble of deep architectures,"S Singh, D Hoiem, D Forsyth - Advances in neural …, 2016 - proceedings.neurips.cc",https://proceedings.neurips.cc/paper/2016/hash/c51ce410c124a10e0db5e4b97fc2af39-Abstract.html,2016,"We describe Swapout, a new stochastic training method, that outperforms ResNets of identical network structure yielding impressive results on CIFAR-10 and CIFAR-100. Swapout samples from a rich set of architectures including dropout, stochastic depth and residual architectures as special cases. When viewed as a regularization method swapout not only inhibits co-adaptation of units in a layer, similar to dropout, but also across network layers. We conjecture that swapout achieves strong regularization by implicitly tying the parameters across layers. When viewed as an ensemble training method, it samples a much richer set of architectures than existing methods such as dropout or stochastic depth. We propose a parameterization that reveals connections to exiting architectures and suggests a much richer set of architectures to be explored. We show that our formulation suggests an efficient training method and validate our conclusions on CIFAR-10 and CIFAR-100 matching state of the art accuracy. Remarkably, our 32 layer wider model performs similar to a 1001 layer ResNet model.","When viewed as an ensemble training method, it samples a much richer set of architectures than existing methods such as dropout or stochastic depth."
27,Deep architecture,"Autoencoders, unsupervised learning, and deep architectures","P Baldi - Proceedings of ICML workshop on unsupervised …, 2012 - proceedings.mlr.press",http://proceedings.mlr.press/v27/baldi12a.html,2012,"
    Autoencoders play a fundamental role in unsupervised learning and in deep architectures for transfer learning and other tasks. In spite of their fundamental role, only linear autoencoders over the real numbers have been solved analytically. Here we present a general mathematical framework for the study of both linear and non-linear autoencoders. The framework allows one to derive an analytical treatment for the most non-linear autoencoder, the Boolean autoencoder. Learning in the Boolean autoencoder is equivalent to a clustering problem that can be solved in polynomial time when the number of clusters is small and becomes NP complete when the number of clusters is large. The framework sheds light on the different kinds of autoencoders, their learning complexity, their horizontal and vertical composability in deep architectures, their critical points, and their fundamental connections to clustering, Hebbian learning, and information theory.
  ","The framework sheds light on the different kinds of autoencoders, their learning complexity, their horizontal and vertical composability in deep architectures, their critical points, and their fundamental connections to clustering, Hebbian learning, and information theory."
28,Deep architecture,From shallow feature learning to deep learning: Benefits from the width and depth of deep architectures,"G Zhong, X Ling, LN Wang - Wiley Interdisciplinary Reviews …, 2019 - Wiley Online Library",https://wires.onlinelibrary.wiley.com/doi/abs/10.1002/widm.1255,2019,"… of the  deep  learning models. Particularly, we survey the  deep    architectures  with benefits from  … Finally, several interesting directions of  deep  learning are presented and briefly discussed. …","Particularly, we survey the  deep    architectures  with benefits from  … Finally, several interesting directions of  deep  learning are presented and briefly discussed."
29,Deep architecture,Sum-product networks: A new deep architecture,"H Poon, P Domingos - 2011 IEEE International Conference on …, 2011 - ieeexplore.ieee.org",https://ieeexplore.ieee.org/abstract/document/6130310/,2011,"The key limiting factor in graphical model inference and learning is the complexity of the partition function. We thus ask the question: what are the most general conditions under which the partition function is tractable? The answer leads to a new kind of deep architecture, which we call sum product networks (SPNs) and will present in this abstract. The key idea of SPNs is to compactly represent the partition function by introducing multiple layers of hidden variables. An SPN is a rooted directed acyclic graph with variables as leaves, sums and products as internal nodes, and weighted edges.",The key limiting factor in graphical model inference and learning is the complexity of the partition function.
30,deep architectures for natural language ,A unified architecture for natural language processing: Deep neural networks with multitask learning,"R Collobert, J Weston - Proceedings of the 25th international conference …, 2008 - dl.acm.org",https://dl.acm.org/doi/abs/10.1145/1390156.1390177,2008,"
We describe a single convolutional neural network architecture that, given a sentence, outputs a host of language processing predictions: part-of-speech tags, chunks, named entity tags, semantic roles, semantically similar words and the likelihood that the sentence makes sense (grammatically and semantically) using a language model. The entire network is trained jointly on all these tasks using weight-sharing, an instance of multitask learning. All the tasks use labeled data except the language model which is learnt from unlabeled text and represents a novel form of semi-supervised learning for the shared tasks. We show how both multitask learning and semi-supervised learning improve the generalization of the shared tasks, resulting in state-of-the-art-performance.
",All the tasks use labeled data except the language model which is learnt from unlabeled text and represents a novel form of semi-supervised learning for the shared tasks.
31,deep architectures for natural language ,Effect of non-linear deep architecture in sequence labeling,"M Wang, CD Manning - … Joint Conference on Natural Language …, 2013 - aclanthology.org",https://aclanthology.org/I13-1183.pdf,2013,"… Random Fields (CRF) with newly proposed “  deep    architecture  ” sequence models (Collobert  et al.… Somewhat surprisingly, we find that a nonlinear  architecture  offers no benefits in a high-…",
32,deep architectures for natural language ,Very deep convolutional networks for natural language processing,"A Conneau, H Schwenk, L Barrault… - arXiv preprint arXiv …, 2016 - researchgate.net",https://www.researchgate.net/profile/Loic-Barrault/publication/303822179_Very_Deep_Convolutional_Networks_for_Natural_Language_Processing/links/5772506308aeeec38953dd26/Very-Deep-Convolutional-Networks-for-Natural-Language-Processing.pdf,2016,"… in NLP is to develop  deep    architectures  which are able to …  deep    architectures  of many  convolutional layers to approach this goal, using up to 29 layers. The design of our  architecture  is …",The design of our  architecture  is …
33,deep architectures for natural language ,Learning deep architectures for AI,"Y Bengio - Foundations and trends® in Machine Learning, 2009 - nowpublishers.com",https://www.nowpublishers.com/article/Details/MAL-006,2009,"Theoretical results suggest that in order to learn the kind of complicated functions that can represent high-level abstractions (e.g., in vision, language, and other AI-level tasks), one may need deep architectures. Deep architectures are composed of multiple levels of non-linear operations, such as in neural nets with many hidden layers or in complicated propositional formulae re-using many sub-formulae. Searching the parameter space of deep architectures is a difficult task, but learning algorithms such as those for Deep Belief Networks have recently been proposed to tackle this problem with notable success, beating the state-of-the-art in certain areas. This monograph discusses the motivations and principles regarding learning algorithms for deep architectures, in particular those exploiting as building blocks unsupervised learning of single-layer models such as Restricted Boltzmann Machines, used to construct deeper models such as Deep Belief Networks.","Searching the parameter space of deep architectures is a difficult task, but learning algorithms such as those for Deep Belief Networks have recently been proposed to tackle this problem with notable success, beating the state-of-the-art in certain areas."
34,deep architectures for natural language ,Deep learning for natural language processing,"Y Xie, L Le, Y Zhou, VV Raghavan - Handbook of statistics, 2018 - Elsevier",https://www.sciencedirect.com/science/article/pii/S0169716118300026,2018,"… Word embedding enables different types of  deep    architecture  to be applied on text in order  to support different machine learning applications. For instance, Recurrent Neural Networks (…","For instance, Recurrent Neural Networks (…"
35,deep architectures for natural language ,Guest editors' introduction: Special section on learning deep architectures,"S Bengio, L Deng, H Larochelle, H Lee… - IEEE transactions on …, 2013 - ieeexplore.ieee.org",https://ieeexplore.ieee.org/abstract/document/6541938/,2013,"There has been a resurgence of research in the design of deep architecture models and learning algorithms, i.e., methods that rely on the extraction of a multilayer representation of the data. Often referred to as deep learning, this topic of research has been building on and contributing to many different research topics, such as neural networks, graphical models, feature learning, unsupervised learning, optimization, pattern recognition, and signal processing. Deep learning is also motivated and inspired by neuroscience and has had a tremendous impact on various applications such as computer vision, speech recognition, and natural language processing. The clearly multidisciplinary nature of deep learning led to a call for papers for a special issue dedicated to learning deep architectures.","Often referred to as deep learning, this topic of research has been building on and contributing to many different research topics, such as neural networks, graphical models, feature learning, unsupervised learning, optimization, pattern recognition, and signal processing."
36,deep architectures for natural language ,A deep architecture for semantic matching with multiple positional sentence representations,"S Wan, Y Lan, J Guo, J Xu, L Pang… - Proceedings of the AAAI …, 2016 - ojs.aaai.org",https://ojs.aaai.org/index.php/AAAI/article/view/10342,2016,"
      
        Matching natural language sentences is central for many applications such as information retrieval and question answering. Existing deep models rely on a single sentence representation or multiple granularity representations for matching. However, such methods cannot well capture the contextualized local information in the matching process. To tackle this problem, we present a new deep architecture to match two sentences with multiple positional sentence representations. Specifically, each positional sentence representation is a sentence representation at this position, generated by a bidirectional long short term memory (Bi-LSTM). The matching score is finally produced by aggregating interactions between these different positional sentence representations, through k-Max pooling and a multi-layer perceptron. Our model has several advantages: (1) By using Bi-LSTM, rich context of the whole sentence is leveraged to capture the contextualized local information in each positional sentence representation; (2) By matching with multiple positional sentence representations, it is flexible to aggregate different important contextualized local information in a sentence to support the matching; (3) Experiments on different tasks such as question answering and sentence completion demonstrate the superiority of our model.
      
    ","Our model has several advantages: (1) By using Bi-LSTM, rich context of the whole sentence is leveraged to capture the contextualized local information in each positional sentence representation; (2) By matching with multiple positional sentence representations, it is flexible to aggregate different important contextualized local information in a sentence to support the matching; (3) Experiments on different tasks such as question answering and sentence completion demonstrate the superiority of our model."
37,deep architectures for natural language ,Image caption generation using a deep architecture,"A Hani, N Tagougui, M Kherallah - 2019 International Arab …, 2019 - ieeexplore.ieee.org",https://ieeexplore.ieee.org/abstract/document/8990998/,2019,"Recently, image captioning is a new challenging task that has gathered widespread interest. The task involves generating a concise description of an image in natural language and is currently accomplished by techniques that use a combination of computer vision (CV), natural language processing (NLP), and machine learning methods.In this paper, we presented a model that generates natural language description of an image. We used a combination of convolutional neural networks to extract features and then used recurrent neural networks to generate text from these features. We incorporated the attention mechanism while generating captions. We evaluated the model on MSCOCO database. The obtained results are promising and competitive.","The task involves generating a concise description of an image in natural language and is currently accomplished by techniques that use a combination of computer vision (CV), natural language processing (NLP), and machine learning methods.In this paper, we presented a model that generates natural language description of an image."
38,deep architectures for natural language ,Text window denoising autoencoder: building deep architecture for Chinese word segmentation,"K Wu, Z Gao, C Peng, X Wen - Natural Language Processing and …, 2013 - Springer",https://link.springer.com/chapter/10.1007/978-3-642-41644-6_1,2013,"Deep learning is the new frontier of machine learning research, which has led to many recent breakthroughs in English natural language processing. However, there are inherent differences between Chinese and English, and little work has been done to apply deep learning techniques to Chinese natural language processing. In this paper, we propose a deep neural network model: text window denoising autoencoder, as well as a complete pre-training solution as a new way to solve classical Chinese natural language processing problems. This method does not require any linguistic knowledge or manual feature design, and can be applied to various Chinese natural language processing tasks, such as Chinese word segmentation. On the PKU dataset of Chinese word segmentation bakeoff 2005, applying this method decreases the F1 error rate by 11.9% for deep neural network based models. We are the first to apply deep learning methods to Chinese word segmentation to our best knowledge.KeywordsDeep LearningWord SegmentationDenoising AutoencoderChinese Natural Language Processing",We are the first to apply deep learning methods to Chinese word segmentation to our best knowledge.KeywordsDeep LearningWord SegmentationDenoising AutoencoderChinese Natural Language Processing
39,deep architectures for natural language ,Implementation of evolutionary algorithms for deep architectures,SS Tirumala - 2014 - researchbank.ac.nz,https://www.researchbank.ac.nz/handle/10652/3963,2014,"… that has been proved with its success in  Natural    Language  Processing (NLP) and image …  circuits,  deep    architectures  can be exponentially efficient than traditional narrow  architectures  in …",
40,object identification using deep learning,Data and its (dis) contents: A survey of dataset development and use in machine learning research,"A Paullada, ID Raji, EM Bender, E Denton, A Hanna - Patterns, 2021 - Elsevier",https://www.sciencedirect.com/science/article/pii/S2666389921001847,2021,"…  work  , we survey recent issues pertaining to data in  machine    learning    research  , focusing  primarily on  work  … such as the ImageNet benchmark for visual  object    recognition  3 and the GLUE …",
41,object identification using deep learning,Car detection for autonomous vehicle: LIDAR and vision fusion approach through deep learning framework,"X Du, MH Ang, D Rus - … Conference on Intelligent Robots and …, 2017 - ieeexplore.ieee.org",https://ieeexplore.ieee.org/abstract/document/8202234/,2017,"Technologies in autonomous vehicles have seen dramatic advances in recent years; however, it still lacks of robust perception systems for car detection. With the recent development in deep learning research, in this paper, we propose a LIDAR and vision fusion system for car detection through the deep learning framework. It consists of three major parts. The first part generates seed proposals for potential car locations in the image by taking LIDAR point cloud into account. The second part refines the location of the proposal boxes by exploring multi-layer information in the proposal network and the last part carries out the final detection task through a detection network which shares part of the layers with the proposal network. The evaluation shows that the proposed framework is able to generate high quality proposal boxes more efficiently (77.6% average recall) and detect the car at the state of the art accuracy (89.4% average precision). With further optimization of the framework structure, it has great potentials to be implemented onto the autonomous vehicle.",The second part refines the location of the proposal boxes by exploring multi-layer information in the proposal network and the last part carries out the final detection task through a detection network which shares part of the layers with the proposal network.
42,object identification using deep learning,Do datasets have politics? Disciplinary values in computer vision dataset development,"MK Scheuerman, A Hanna, E Denton - … of the ACM on Human-Computer …, 2021 - dl.acm.org",https://dl.acm.org/doi/abs/10.1145/3476058,2021,"Data is a crucial component of machine learning. The field is reliant on data to train, validate, and test models. With increased technical capabilities, machine learning research has boomed in both academic and industry settings, and one major focus has been on computer vision. Computer vision is a popular domain of machine learning increasingly pertinent to real-world applications, from facial recognition in policing to object detection for autonomous vehicles. Given computer vision's propensity to shape machine learning research and impact human life, we seek to understand disciplinary practices around dataset documentation - how data is collected, curated, annotated, and packaged into datasets for computer vision researchers and practitioners to use for model tuning and development. Specifically, we examine what dataset documentation communicates about the underlying values of vision data and the larger practices and goals of computer vision as a field. To conduct this study, we collected a corpus of about 500 computer vision datasets, from which we sampled 114 dataset publications across different vision tasks. Through both a structured and thematic content analysis, we document a number of values around accepted data practices, what makes desirable data, and the treatment of humans in the dataset construction process. We discuss how computer vision datasets authors value efficiency at the expense of care; universality at the expense of contextuality; impartiality at the expense of positionality; and model work at the expense of data work. Many of the silenced values we identify sit in opposition with social computing practices. We conclude with suggestions on how to better incorporate silenced values into the dataset creation and curation process.","Specifically, we examine what dataset documentation communicates about the underlying values of vision data and the larger practices and goals of computer vision as a field."
43,object identification using deep learning,The values encoded in machine learning research,"A Birhane, P Kalluri, D Card, W Agnew… - … , Accountability, and …, 2022 - dl.acm.org",https://dl.acm.org/doi/abs/10.1145/3531146.3533083,2022,"
Machine learning currently exerts an outsized influence on the world, increasingly affecting institutional practices and impacted communities. It is therefore critical that we question vague conceptions of the field as value-neutral or universally beneficial, and investigate what specific values the field is advancing. In this paper, we first introduce a method and annotation scheme for studying the values encoded in documents such as research papers. Applying the scheme, we analyze 100 highly cited machine learning papers published at premier machine learning conferences, ICML and NeurIPS. We annotate key features of papers which reveal their values: their justification for their choice of project, which attributes of their project they uplift, their consideration of potential negative consequences, and their institutional affiliations and funding sources. We find that few of the papers justify how their project connects to a societal need (15%) and far fewer discuss negative potential (1%). Through line-by-line content analysis, we identify 59 values that are uplifted in ML research, and, of these, we find that the papers most frequently justify and assess themselves based on Performance, Generalization, Quantitative evidence, Efficiency, Building on past work, and Novelty. We present extensive textual evidence and identify key themes in the definitions and operationalization of these values. Notably, we find systematic textual evidence that these top values are being defined and applied with assumptions and implications generally supporting the centralization of power. Finally, we find increasingly close ties between these highly cited papers and tech companies and elite universities. 
","Through line-by-line content analysis, we identify 59 values that are uplifted in ML research, and, of these, we find that the papers most frequently justify and assess themselves based on Performance, Generalization, Quantitative evidence, Efficiency, Building on past work, and Novelty."
44,object identification using deep learning,"1.1 deep learning hardware: past, present, and future","Y LeCun - 2019 IEEE International Solid-State Circuits …, 2019 - ieeexplore.ieee.org",https://ieeexplore.ieee.org/abstract/document/8662396/,2019,"Historically, progress in neural networks and deep learning research has been greatly influenced by the available hardware and software tools. This paper identifies trends in deep learning research that will influence hardware architectures and software platforms of the future.",This paper identifies trends in deep learning research that will influence hardware architectures and software platforms of the future.
45,object identification using deep learning,"Reduced, reused and recycled: The life of a dataset in machine learning research","B Koch, E Denton, A Hanna, JG Foster - arXiv preprint arXiv:2112.01716, 2021 - arxiv.org",https://arxiv.org/abs/2112.01716,2112," Benchmark datasets play a central role in the organization of machine
learning research. They coordinate researchers around shared research problems
and serve as a measure of progress towards shared goals. Despite the
foundational role of benchmarking practices in this field, relatively little
attention has been paid to the dynamics of benchmark dataset use and reuse,
within or across machine learning subcommunities. In this paper, we dig into
these dynamics. We study how dataset usage patterns differ across machine
learning subcommunities and across time from 2015-2020. We find increasing
concentration on fewer and fewer datasets within task communities, significant
adoption of datasets from other tasks, and concentration across the field on
datasets that have been introduced by researchers situated within a small
number of elite institutions. Our results have implications for scientific
evaluation, AI ethics, and equity/access within the field.
","Despite the
foundational role of benchmarking practices in this field, relatively little
attention has been paid to the dynamics of benchmark dataset use and reuse,
within or across machine learning subcommunities."
46,object identification using deep learning,Hierarchical object detection with deep reinforcement learning,"MB Bueno, XG Nieto, F Marqués… - Deep Learning for Image …, 2017 - books.google.com",https://books.google.com/books?hl=en&lr=&id=vsFVDwAAQBAJ&oi=fnd&pg=PA164&dq=+object+identification+using+deep+learningresearch+papers&ots=-1JhJstbpi&sig=YRcZUA-A6Stbk_zGBmQT1t6ifAk,2017,… This  work  introduces a model for Hierarchical  Object    Detection  with  Deep  Reinforcement …  We compare two different candidate proposal strategies to guide the  object  search: with and …,
47,object identification using deep learning,Orientation robust object detection in aerial images using deep convolutional neural network,"H Zhu, X Chen, W Dai, K Fu, Q Ye… - 2015 IEEE International …, 2015 - ieeexplore.ieee.org",https://ieeexplore.ieee.org/abstract/document/7351502/,2015,"Detecting objects in aerial images is challenged by variance of object colors, aspect ratios, cluttered backgrounds, and in particular, undetermined orientations. In this paper, we propose to use Deep Convolutional Neural Network (DCNN) features from combined layers to perform orientation robust aerial object detection. We explore the inherent characteristics of DC-NN as well as relate the extracted features to the principle of disentangling feature learning. An image segmentation based approach is used to localize ROIs of various aspect ratios, and ROIs are further classified into positives or negatives using an SVM classifier trained on DCNN features. With experiments on two datasets collected from Google Earth, we demonstrate that the proposed aerial object detection approach is simple but effective.","In this paper, we propose to use Deep Convolutional Neural Network (DCNN) features from combined layers to perform orientation robust aerial object detection."
48,object identification using deep learning,Geometric deep learning on graphs and manifolds using mixture model cnns,"F Monti, D Boscaini, J Masci… - … pattern recognition, 2017 - openaccess.thecvf.com",http://openaccess.thecvf.com/content_cvpr_2017/html/Monti_Geometric_Deep_Learning_CVPR_2017_paper.html,2017,"
Deep learning has achieved a remarkable performance breakthrough in several fields, most notably in speech recognition, natural language processing, and computer vision. In particular, convolutional neural network (CNN) architectures currently produce state-of-the-art performance on a variety of image analysis tasks such as object detection and recognition. Most of deep learning research has so far focused on dealing with 1D, 2D, or 3D Euclidean-structured data such as acoustic signals, images, or videos. Recently, there has been an increasing interest in geometric deep learning, attempting to generalize deep learning methods to non-Euclidean structured data such as graphs and manifolds, with a variety of applications from the domains of network analysis, computational social science, or computer graphics. In this paper, we propose a unified framework allowing to generalize CNN architectures to non-Euclidean domains (graphs and manifolds) and learn local, stationary, and compositional task-specific features. We show that various non-Euclidean CNN methods previously proposed in the literature can be considered as particular instances of our framework. We test the proposed method on standard tasks from the realms of image-, graph- and 3D shape analysis and show that it consistently outperforms previous approaches.","Recently, there has been an increasing interest in geometric deep learning, attempting to generalize deep learning methods to non-Euclidean structured data such as graphs and manifolds, with a variety of applications from the domains of network analysis, computational social science, or computer graphics."
49,object identification using deep learning,Logo-net: Large-scale deep logo detection and brand recognition with deep region-based convolutional networks,"SCH Hoi, X Wu, H Liu, Y Wu, H Wang, H Xue… - arXiv preprint arXiv …, 2015 - arxiv.org",https://arxiv.org/abs/1511.02462,2015," Logo detection from images has many applications, particularly for brand
recognition and intellectual property protection. Most existing studies for
logo recognition and detection are based on small-scale datasets which are not
comprehensive enough when exploring emerging deep learning techniques. In this
paper, we introduce ""LOGO-Net"", a large-scale logo image database for logo
detection and brand recognition from real-world product images. To facilitate
research, LOGO-Net has two datasets: (i)""logos-18"" consists of 18 logo classes,
10 brands, and 16,043 logo objects, and (ii) ""logos-160"" consists of 160 logo
classes, 100 brands, and 130,608 logo objects. We describe the ideas and
challenges for constructing such a large-scale database. Another key
contribution of this work is to apply emerging deep learning techniques for
logo detection and brand recognition tasks, and conduct extensive experiments
by exploring several state-of-the-art deep region-based convolutional networks
techniques for object detection tasks. The LOGO-net will be released at
http://logo-net.org/
","In this
paper, we introduce ""LOGO-Net"", a large-scale logo image database for logo
detection and brand recognition from real-world product images."
50,object detection using deep architecture,Evaluation methods and replicability of software architecture research objects,"M Konersmann, A Kaplan, T Kühn… - 2022 IEEE 19th …, 2022 - ieeexplore.ieee.org",https://ieeexplore.ieee.org/abstract/document/9779698/,2022,"Context: Software architecture (SA) as research area experienced an increase in empirical research, as identified by Galster and Weyns in 2016 [1]. Empirical research builds a sound foundation for the validity and comparability of the research. A current overview on the evaluation and replicability of SA research objects could help to discuss our empirical standards as a community. However, no such current overview exists.Objective: We aim at assessing the current state of practice of evaluating SA research objects and replication artifact provision in full technical conference papers from 2017 to 2021.Method: We first create a categorization of papers regarding their evaluation and provision of replication artifacts. In a systematic literature review (SLR) with 153 papers we then investigate how SA research objects are evaluated and how artifacts are made available.Results: We found that technical experiments (28%) and case studies (29%) are the most frequently used evaluation methods over all research objects. Functional suitability (46% of evaluated properties) and performance (29%) are the most evaluated properties. 17 papers (11%) provide replication packages and 97 papers (63%) explicitly state threats to validity. 17% of papers reference guidelines for evaluations and 14% of papers reference guidelines for threats to validity.Conclusions: Our results indicate that the generalizability and repeatability of evaluations could be improved to enhance the maturity of the field; although, there are valid reasons for contributions to not publish their data. We derive from our findings a set of four proposals for improving the state of practice in evaluating software architecture research objects. Researchers can use our results to find recommendations on relevant properties to evaluate and evaluation methods to use and to identify reusable evaluation artifacts to compare their novel ideas with other research. Reviewers can use our results to compare the evaluation and replicability of submissions with the state of the practice.",Reviewers can use our results to compare the evaluation and replicability of submissions with the state of the practice.
51,object detection using deep architecture,"The past, present, and future for software architecture","P Kruchten, H Obbink, J Stafford - IEEE software, 2006 - ieeexplore.ieee.org",https://ieeexplore.ieee.org/abstract/document/1605175/,2006,"It's been 10 years since David Garlan and Mary Shaw wrote their seminal book Software Architecture Perspective on an Emerging Discipline, since Maarten Boasson edited a special issue of IEEE Software on software architecture, and since the first International Software Architecture Workshop took place. What has happened over these 10 years? What have we learned? Where do we look for information? What's the community around this discipline? And where are we going from here?This article is part of a focus section on software architecture.",And where are we going from here?This article is part of a focus section on software architecture.
52,object detection using deep architecture,"A review of 40 years of cognitive architecture research: Focus on perception, attention, learning and applications","I Kotseruba, OJA Gonzalez… - arXiv preprint arXiv …, 2016 - researchgate.net",https://www.researchgate.net/profile/John-Tsotsos/publication/309483878_A_Review_of_40_Years_of_Cognitive_Architecture_Research_Focus_on_Perception_Attention_Learning_and_Applications/links/58148e1c08aedc7d8963b93b/A-Review-of-40-Years-of-Cognitive-Architecture-Research-Focus-on-Perception-Attention-Learning-and-Applications.pdf,2016,… In this  paper  we present a broad overview of the last 40 … To keep the length of this  paper    within reasonable limits we … for features when learning invariant  object    detection  [42]. In [43] the …,In [43] the …
53,object detection using deep architecture,A review of 40 years of cognitive architecture research: Core cognitive abilities and practical applications,"I Kotseruba, JK Tsotsos - arXiv preprint arXiv:1610.08602, 2016 - arxiv.org",https://arxiv.org/abs/1610.08602,1610," In this paper we present a broad overview of the last 40 years of research on
cognitive architectures. Although the number of existing architectures is
nearing several hundred, most of the existing surveys do not reflect this
growth and focus on a handful of well-established architectures. Thus, in this
survey we wanted to shift the focus towards a more inclusive and high-level
overview of the research on cognitive architectures. Our final set of 84
architectures includes 49 that are still actively developed, and borrow from a
diverse set of disciplines, spanning areas from psychoanalysis to neuroscience.
To keep the length of this paper within reasonable limits we discuss only the
core cognitive abilities, such as perception, attention mechanisms, action
selection, memory, learning and reasoning. In order to assess the breadth of
practical applications of cognitive architectures we gathered information on
over 900 practical projects implemented using the cognitive architectures in
our list. We use various visualization techniques to highlight overall trends
in the development of the field. In addition to summarizing the current
state-of-the-art in the cognitive architecture research, this survey describes
a variety of methods and ideas that have been tried and their relative success
in modeling human cognitive abilities, as well as which aspects of cognitive
behavior need more research with respect to their mechanistic counterparts and
thus can further inform how cognitive science might progress.
","Thus, in this
survey we wanted to shift the focus towards a more inclusive and high-level
overview of the research on cognitive architectures."
54,object detection using deep architecture,Smart classrooms aided by deep neural networks inference on mobile devices,"A Pacheco, E Flores, R Sánchez… - … on Electro/Information …, 2018 - ieeexplore.ieee.org",https://ieeexplore.ieee.org/abstract/document/8500260/,2018,"Machine Learning over edge computing devices is levering up embedded and IoT intelligence and is expected to grow even more. Today, Machine Learning applications are mainly driven by Cloud Computing, but a recent trend towards on-device ML execution is taken over. We can expect that in coming years there will be smart homes and buildings populated by much more smart devices able to assist human activities more naturally. We present a work in progress, a mobile edge computing prototype built to explore and validate how ready are smartphones for on-device execution of deep neural networks (DNNs) using as a test bed a light control of a smart classroom via object recognition using three pre-trained non-optimized DNN models embedded in one mobile app. The prototype was successfully accomplished for recognition and control tasks using only smartphone's CPU/GPU processing units to run DNN models under 670ms. Finally, on-device DNN inference performance is discussed and some future work issues are presented.",Machine Learning over edge computing devices is levering up embedded and IoT intelligence and is expected to grow even more.
55,object detection using deep architecture,Enabling Architecture Research on GPU Simulator for Deep Learning Applications,AD Nikam - 2018 - search.proquest.com,https://search.proquest.com/openview/734b7773ef9d910874965cc43412614f/1?pq-origsite=gscholar&cbl=18750,2018,"… for applications such as real time  object    detection  , embedded GPUs performance seems …  Fig 4.6 shows Matrix multiplication  using  Shared memory and increasing the  work  done per …",
56,object detection using deep architecture,Dilemmas in enterprise architecture research and practice from a perspective of feral information systems,"T Tambo, L Bækgaard - … Enterprise Distributed Object …, 2013 - ieeexplore.ieee.org",https://ieeexplore.ieee.org/abstract/document/6690564/,2013,"This paper is presenting a discussion of feral information systems (FIS) in relationship to enterprise architecture (EA) thereby aiming to better qualify the architectural understanding of information systems not in line with corporate IT/IS strategy and policies. A qualitative and case-based approach is used as empirical foundation of this paper. With users developing own IS, classical strategy-based EA approaches are challenged. Identifying FIS can strongly improve insight into organizational processes and shortcomings official EA. A functional and temporal perspective is proposed to guide EA processes to embrace unofficial, user-driven systems. As FIS tend not to follow any rules of corporate IS, EA embrace of FIS is more complex. Using a meta-model for the social and operational character of FIS this complexity can be managed along with the improve business insight. The recognition of FIS in EA both opens up for insight in local adaptations of business processes, but can also create room for low-cost innovation and rapid response to changes in business conditions. Several forecasts are suggesting corporate IT/IS to be more user-driven and with reduced control from IT/IS professionals. This paper is opening a discussion on EA practice when centralized control is assumed to decline. EA has a tendency to be developed ""top-down"" emphasizing strategic alignment. In this contributed it is suggested to include social and operational alignment in EA practice.",This paper is presenting a discussion of feral information systems (FIS) in relationship to enterprise architecture (EA) thereby aiming to better qualify the architectural understanding of information systems not in line with corporate IT/IS strategy and policies.
57,object detection using deep architecture,Multi-Domain Thermal Object Detection Using Generative Adversarial Networks,"M Eltahan, K Elsayed - 2022 International Conference on …, 2022 - ieeexplore.ieee.org",https://ieeexplore.ieee.org/abstract/document/10034641/,2022,"The major recent advances in autonomous driving are mostly based on recent progress in object detection methods. Object detection broadly depends on the quality of the cameras and sensors used to generate the images. Many kinds of sensors are being utilized for the sake of improving scene perception, such as RGB, radar, and LiDAR. However, the usage of all these sensors' data leads to object detection degradation in adverse lighting conditions. Thermal imaging depicts the spatial distribution of temperature differences in a scene. This leads to the ability of a thermal camera to outperform other sensors in severe weather conditions. In this research, we propose the use of thermal imaging to improve object detection in autonomous driving. The proposed framework inherits the architecture of EfficientDet and further proposes a technique to fuse the features of two different modalities: thermal and RGB. We use GAN as an I2I translation framework to transform the thermal images into RGB images. The experimental results demonstrate that the proposed framework outperforms the detection accuracy of other state-of-the-art object detectors in thermal imagery. We propose two variants, MDFFTDet-D0 and MDFFTDet-D2 which achieve mAP of 63.15% and 77.81% respectively on the FLIR ADAS dataset.","In this research, we propose the use of thermal imaging to improve object detection in autonomous driving."
58,object detection using deep architecture,Real-Time Robust Video Object Detection System Against Physical-World Adversarial Attacks,"H Han, X Hu, K Xu, P Dang, Y Wang, Y Zhao… - arXiv preprint arXiv …, 2022 - arxiv.org",https://arxiv.org/abs/2208.09195,2022," DNN-based video object detection (VOD) powers autonomous driving and video
surveillance industries with rising importance and promising opportunities.
However, adversarial patch attack yields huge concern in live vision tasks
because of its practicality, feasibility, and powerful attack effectiveness.
This work proposes Themis, a software/hardware system to defend against
adversarial patches for real-time robust video object detection. We observe
that adversarial patches exhibit extremely localized superficial feature
importance in a small region with non-robust predictions, and thus propose the
adversarial region detection algorithm for adversarial effect elimination.
Themis also proposes a systematic design to efficiently support the algorithm
by eliminating redundant computations and memory traffics. Experimental results
show that the proposed methodology can effectively recover the system from the
adversarial attack with negligible hardware overhead.
","We observe
that adversarial patches exhibit extremely localized superficial feature
importance in a small region with non-robust predictions, and thus propose the
adversarial region detection algorithm for adversarial effect elimination."
59,object detection using deep architecture,Cybersecurity risk analysis and technical defense architecture: Research of ICS in nuclear power plant construction stage,"Y Guo, X Lou, E Bajramovic… - Proceedings of the 3rd …, 2020 - conferences.iaea.org",https://conferences.iaea.org/event/181/contributions/15923/attachments/8492/11271/CN278_Paper_Submission_YUNGUO_with_id_615.pdf,2020,"… test platform is to  use  real equipment, which also means high investment cost and inflexibility  of changes. The authors of this  paper  also put forward an idea of  using  DT (Digital Twinning…",The authors of this  paper  also put forward an idea of  using  DT (Digital Twinning…
